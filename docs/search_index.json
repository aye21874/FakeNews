[["index.html", "Exploring Fake News through LIAR dataset Chapter 1 Introduction", " Exploring Fake News through LIAR dataset Andrew Schaefer, Angad Nandwani and Ayush Sinha 2021-12-13 Chapter 1 Introduction Recently, the consumption of global news and its authenticity has become a considerable challenge. Social Media platforms like Facebook, Twitter enables us to access news anywhere, but they also have the equal potential to spread Fake News, thereby delivering false information. This definitely has a huge negative impact on the society, thereby making it necessary to determine whether the news is fake or factual. Automatic fake news detection is a challenging problem in deception detection, and it has tremendous potential on real-world political and social impacts. One of the datasets which allow us to build models and predict fake news is Liar Detection. This dataset has has 12,800 human labelled short statements in various contexts related to politics, and useful for the fact-checking research for news. In this project, we have used this dataset to explore the following questions/statements through exploratory data analysis. Questions/Statements 1) Which positions of authority lead to Fake &amp; Factual information? Which party tends to spread Fake News More? 2) What are the most selected Topic/Subject picked by each Speaker which has the highest tendency of spreading Fake News? 3) Which are the states spreading maximum number of false counts, also noting the count of different speakers involved in spreading Fake News? 4) The most prone Fake News method of communication, State Wise. 5) Correlation, Clusters &amp; Outliers observed for different Mediums/Platforms in spreading Fake News for each State. 6) Count of Words in Statment and its relationship with Label for the News. Overall, through visualization, we have tried to find out the most reliable method of receiving correct information, which platforms we can pay attention to for controversial topics, and the suspicious figures we should avoid for getting the correct information. References Ternion: An Autonomous Model for Fake News Detection - “Noman Islam, Asadullah Shaikh, Asma Qaiser, Yousef Asiri, Sultan Almakdi, Adel Sulaiman Verdah Moazzam and Syeda Aiman Babar”. “Liar, Liar Pants on Fire”: A New Benchmark Dataset for Fake News Detection - William Yang Wang John A. Bernau, PHD - Research Blog on Text Analysis "],["data-sources.html", "Chapter 2 Data sources", " Chapter 2 Data sources In the beginning of the semester, we participated in the columbia data science hackathon event, where we recieved the LIAR dataset. The topic of Fake News Detection and the dataset intrigued us to find more insides on the relationship between dependendent and independent features. The Liar dataset have 12,800 human labelled short statements in various context related to politics and it is evaluated by the politifact.com editor for its truthfulness. Below are the some useful links Columbia Data Science Hackathon Page ‘ 2021 - https://cdssatcu.com/2021-data-science-hackathon Actual Dataset - https://www.cs.ucsb.edu/~william/data/liar_dataset.zip Dataset Evaluation by Politifact.com - https://www.politifact.com/ Below is the description of the features present in the dataset. 1) ID - Unique Row ID associated for each Statement. 2) Label - Statements were “True”, “False”, “Barely-True”, “Half-True”, “Mostly-True”, “Pants-Fire”. 3) Statement - Sentences of words varying between 5 to 5000. 4) Subject - The topic related to Statement. Like HealthCare, Jobs Etc. 5) Speaker - The person who has given the statement. 6) SpeakerJobTitle - The title associated with the speaker. Like Preisdent, Governor etc. 7) StateInfo - The state where the statement was made. 8) Party Affiliated - The party the speaker belong to. Like Republican, Democratic, Independent. 9) Barely True Counts - The accumulation of Barely True counts associated with Speaker. 10) False Counts - The accumulation of False Counts associated with Speaker. 11) Half False Counts - The accumulation of Half False Counts associated with Speaker. 12) Mostly True Counts - The accumulation of Mostly True Counts associated with Speaker. 13) Pants Fire Counts - The accumulation of Pants Fire Counts associated with Speaker. 14) Venue/Location - The Medium through which News was Spread. Like Television, Radio etc. "],["data-transformation.html", "Chapter 3 Data transformation", " Chapter 3 Data transformation Below Steps were used for transforming the dataset The first step in the cleaning is to concatenate the 3 files. We merged the train, test and validate files into 1 file, fakeNewsClean.csv. We did this as the task was related to exploring data through visualization, and no modelling of data was required. The three files together will help us to have a better understanding of overall data distribution. In the process of generating new file, we also replaced ID Column with a new ID column consisting of numbers from 1 to number of rows in dataframe. We saw most of the columns in the data had 2 rows missing. Taking a closer look, the rows with ID 5872, and 8180 had most of the columns missing. So we removed those 2 rows from the dataset. For The columns Subject, SpeakerJobTitle, Speaker, Venue/Location, “The Party Affiliation”, we choose to replace missing values with a new category “Unknown”. This will be a new category helps us to understand where data was missing and how it is related to each questions. Below is the Projection of Missing values for each column for each column in the dataset. ## Speaker Job Title State Info Venue/Location ## 3170 2446 110 ## Subject(s) Speaker The Party Affiliation ## 2 2 2 ## Barely True Counts False Counts Half True Counts ## 2 2 2 ## Mostly True Counts Pants on Fire Counts ID ## 2 2 0 ## Label Statement ## 0 0 After Cleaning ## ID Label Statement ## 0 0 0 ## Subject(s) Speaker Speaker Job Title ## 0 0 0 ## State Info The Party Affiliation Barely True Counts ## 0 0 0 ## False Counts Half True Counts Mostly True Counts ## 0 0 0 ## Pants on Fire Counts Venue/Location ## 0 0 For columns Venue, Subject and SpeakerJobTitle, StateInfo, PartyAffiliation we followed the below steps for pre-processing For each sentence in the following column :- :- Converted each sentence to lower case :- Removed all Punctuations :- Removed extra whitespaces :- split the sentences into words by delimiter = &quot; &quot; :- Removed Stop-Words :- Concatenated the words to form the sentence For Venue, Subject and SpeakerJobTitle, we also did an extra step to group similar words together. For example Venue like Tweet, Tweets, Tweet! were all grouped into 1 group using “group_str” function. Using all the steps we have created a new file, FakeNews_Clean.csv which we will be using for taking insides to our questions. "],["missing-values.html", "Chapter 4 Missing values", " Chapter 4 Missing values Below are some key observations with respect to Missing Values in the dataset. Missing values by column for the Liar dataset ## Speaker Job Title State Info Venue/Location ## 3170 2446 110 ## Subject(s) Speaker The Party Affiliation ## 2 2 2 ## Barely True Counts False Counts Half True Counts ## 2 2 2 ## Mostly True Counts Pants on Fire Counts ID ## 2 2 0 ## Label Statement ## 0 0 It is important to note that Label column (independent feature) doesn’t have missing values in the dataset. Most of the columns have 2 missing values, which after taking a closer look belongs to ID’s 5872 and 8180 Speaker Job Title has maximum missing values - 3170 Top 30 row-id having maximum missing values ## 5872 8180 921 1137 1274 2584 2834 3622 3645 4020 5845 6058 6279 ## 11 11 3 3 3 3 3 3 3 3 3 3 3 ## 6553 6603 8125 8172 8222 8952 9323 9583 9752 10096 10434 10667 10871 ## 3 3 3 3 3 3 3 3 3 3 3 3 3 ## 11120 3 8 13 ## 3 2 2 2 Maximum number of columns having missing values in a row are 11. For examples Id’s like 5872, 8180 etc. have 11 columns with missing values. Heatmap Since we noticed that “Speaker Job Title” and “State Info” had maximum missing values, we used heatmaps to see if we can observe any pattern. Below are the observed patterns :- For “Speaker Job Title”, True &amp; False Staements were completely missing. For “State Info” feature, False Statements were completely missing. Missing propotions "],["results.html", "Chapter 5 Results", " Chapter 5 Results Question 1 : Which positions of authority lead to Fake &amp; Factual information? Which Party tends to spread Fake News More? Observation from Graph 1 President, Governor &amp; Senators from different Party are most popular “Speaker Job Titles” in spreading both Fake &amp; Factual News. The “President Elect” &amp; “Predient Candidate” had almost equal counts for spreading Fake or Factual News Senators from the Party lead the count for spreading information, for both Factual &amp; Fake. The graph also demonstrates highest Pants-Fire count for Senators, deonting that they are the one’s with most latest information related to Party. For any “Speaker Job Title”, the counts for mostly-true labels were higher than the true. House Officials have the least power in spreading Fake or Factual News. The overall projects in counts for False and Barely True lead the other labels, signifying that almost all Speaker Job Titles from Graph spread high propotion of Fake News. Observation from Graph 2 Republican Party is more prone towards spreading Fake News. The Propotion of Half-True is more than False for almost all Speakers belonging to any party. This tells us that significane of some truth in any given statement is high. Question 2: What are the most selected topic/Subject picked by each Speaker which has the highest tendency of Spreading Fake News\" Observation from Graph Senators have spread Fake News in highest propotion with respect to every topic demonstrated in graph President Candidate had Fake News only related to Immigration President didn’t had Fake News related to topics like Military, Abortion, Debts, Jobs, Economy, Only Senators and President had fake news related to topics :- Fires, Iraq, Israel, Islam, Foreign Policy, Fedral Budge, Energy. Education Subject had the highest count for fake news and the most selected topic by any speaker. The Propotion of Half-True is more than False for almost all Speakers belonging to any party. This tells us that significane of some truth in any given statement is high. Question 3:- States Spreading maximum number of false counts, noting the count of different speakers involved in spreading Fake News Observation from the Graphs Above Graph gives a clear idea for the count of Fake News in each State. The larger the rectangle, the state had more number of Fake News Spread. The color is mapped with the different number of speakers involved in that state to spread Fake News. There were lot of states in the dataset which were labelled Unknown while pre-processing, which apparently are also spreading Fake News in high propotions Texas is most widely known state to spread Fake News with about 400+ different Speakers involved in spreading Fake News Count of Fake News Spread is closely related with the different number of Speakers spreading the news. North Carolina, Tennessee, Colorado, Alaska etc, which share the same size, have least number of different speakers observed. New York, Wisconsin and Florida have almost equal number of counts in spreading Fake News, which are compartively high when compare to other states. Also, Wisconsin and New York share the same count for number of speakers but the Florida has most number of different speakers among the 3, spreading the Fake News. Question 4 :- The Most Prone Fake News Method of communication, State Wise Observation from Graph Below are the few names of venues (platforms) state wise which were used maximum times to spread fake news Florida, Texas, California, Indiana, Maryland, Missouri, North Carolina mostly uses Press Release as the mediumn for fake news. Georgia, Illinois, Pennsylvania, Virginia mostly uses Speeches as the medium for fake news. Since the states map imported from library had more states than the states present in our dataframe, we obderved NA in the graph. We didn’t had the information related to “most widely platforms used” to spreak fake news. Our Grouping of Venue Like Tweets/Tweet to Tweet might not be that accurate as we have used group_str to do the concatenation with the distance of similarity as 3 between words. This parameter can be manipualated for better efficiency. Question 5:- Correlation, Clusters &amp; Outliers observed for different Mediums/Platforms in spreading Fake News for each State Observation from the Graphs The count for OnlineInterview Medium for spreading Fake News was mostly less (&lt;10) for most of the regions, except Wisconscin, Texas and Florida. Most of the States, who have used Press Release for spreading Fake News, have also used News Release. We observed Positive Correlation between these two mediums for almost all the regions Similarly, we noticed negative correlation between News Release and TV Advertisement. Those states which have used News Release have a reduce count for the TV Advertisement We noticed wide range of differences in count between New York &amp; Jersy for each above mentioned platform in graohw which suggest different political administration. Even Tweeter, the most popular online social platform waas not used as the medium to spread Fake News for these states. Question 6: Count of Words in Statment and its relationship with Label for the News Observation from the Graphs For Statements between 100 and 1000 Words, The propotion for the True Labels are high with the word counts less than 300 in the statements made by any speaker All Speakers had False Count in more propotion over True Count. Question 7 : What are the states with maximum proportions of fake news and in what subject? Which subject has the most concentrated fake news? Question 8 : Most dishonest States and which Subjects Question 9 : Distribution of Factual News with respect to state Question 10 : The most controversial Subjects **Question 11 : *Origin of Fake Vs Factual News with respect to Venue, Party &amp; Job Title** "],["interactive-component.html", "Chapter 6 Interactive component", " Chapter 6 Interactive component "],["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
